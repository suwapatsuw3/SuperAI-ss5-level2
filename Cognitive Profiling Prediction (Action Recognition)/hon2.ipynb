{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbbe398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp_pose_module\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66dc8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos:   0%|          | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing: copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov\n",
      "   video.fps: 24\n",
      "   video.duration: 1861.82\n",
      "   video.size: [2560, 1440]\n",
      "Moviepy - Building video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4.\n",
      "MoviePy - Writing audio in copy_B52269A0-899E-43A0-A841-93F6DBDD7A9FTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.82s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4\n",
      "\n",
      "‚ö†Ô∏è Failed to convert copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "output_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "\n",
    "# Get a list of all .mov files in the input folder\n",
    "mov_files = [filename for filename in os.listdir(input_folder) if filename.endswith(\".mov\")]\n",
    "\n",
    "# Loop through all .mov files and show estimated progress with a progress bar\n",
    "for filename in tqdm(mov_files, desc='Converting videos', unit='video'):\n",
    "    input_file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    try:\n",
    "        # Load the .mov file\n",
    "        video = VideoFileClip(input_file_path).set_fps(24)\n",
    "\n",
    "        # Safely get fps\n",
    "        fps = video.fps if video.fps else 24\n",
    "\n",
    "        # Check video properties\n",
    "        if video.duration is None or video.size is None:\n",
    "            print(f\"‚ùå Skipping {filename} ‚Äî missing duration or size\")\n",
    "            continue\n",
    "\n",
    "        # Construct output file path\n",
    "        output_filename = os.path.splitext(filename)[0] + \".mp4\"\n",
    "        output_file_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        print(f\"\\nüé¨ Processing: {filename}\")\n",
    "        print(\"   video.fps:\", fps)\n",
    "        print(\"   video.duration:\", video.duration)\n",
    "        print(\"   video.size:\", video.size)\n",
    "\n",
    "        # Write the video to output\n",
    "        video.write_videofile(output_file_path, codec='libx264', fps=fps)\n",
    "\n",
    "        # Manual frame progress bar (optional)\n",
    "        total_frames = int(video.duration * fps)\n",
    "        progress = 0\n",
    "        with tqdm(total=total_frames, desc=f'{filename}', unit='frame') as pbar:\n",
    "            while progress < total_frames:\n",
    "                progress = video.reader.nframes\n",
    "                pbar.update(progress - pbar.n)\n",
    "\n",
    "        video.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to convert {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b17353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos:   0%|          | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing: copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos:   0%|          | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   video.fps: 24.0\n",
      "   video.duration: 1861.82\n",
      "   video.size: [2560, 1440]\n",
      "   video.has_audio: True\n",
      "Moviepy - Building video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4.\n",
      "MoviePy - Writing audio in copy_B52269A0-899E-43A0-A841-93F6DBDD7A9FTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.50s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4\n",
      "\n",
      "‚ö†Ô∏è Failed to convert copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "output_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "\n",
    "mov_files = [f for f in os.listdir(input_folder) if f.endswith(\".mov\")]\n",
    "\n",
    "for filename in tqdm(mov_files, desc='Converting videos', unit='video'):\n",
    "    try:\n",
    "        print(f\"\\nüé¨ Processing: {filename}\")\n",
    "        input_file_path = os.path.join(input_folder, filename)\n",
    "        output_filename = os.path.splitext(filename)[0] + \".mp4\"\n",
    "        output_file_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        video = VideoFileClip(input_file_path)\n",
    "        fps = video.fps or 24\n",
    "        duration = video.duration or 0\n",
    "        size = video.size\n",
    "\n",
    "        print(\"   video.fps:\", fps)\n",
    "        print(\"   video.duration:\", duration)\n",
    "        print(\"   video.size:\", size)\n",
    "        print(\"   video.has_audio:\", video.audio is not None)\n",
    "\n",
    "        # Set fps explicitly\n",
    "        video = video.set_fps(fps)\n",
    "\n",
    "        # Check and validate audio\n",
    "        has_audio = False\n",
    "        if video.audio is not None:\n",
    "            try:\n",
    "                _ = video.audio.fps\n",
    "                _ = video.audio.duration\n",
    "                _ = video.audio.nchannels\n",
    "                has_audio = True\n",
    "            except Exception as audio_err:\n",
    "                print(\"‚ö†Ô∏è Corrupted audio detected ‚Äî stripping audio.\")\n",
    "                video = video.without_audio()\n",
    "\n",
    "        # Write video with or without audio\n",
    "        video.write_videofile(\n",
    "            output_file_path,\n",
    "            codec='libx264',\n",
    "            fps=fps,\n",
    "            audio=has_audio,\n",
    "            audio_codec='aac' if has_audio else None,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to convert {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7605172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s06_smiley.mp4: FPS = 25.0\n"
     ]
    }
   ],
   "source": [
    "video_dir = Path('/home/siamai/data/Penguin/week7/test')\n",
    "\n",
    "for video_file in video_dir.glob(\"*.mp4\"):\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"{video_file.name}: FPS = {fps}\")\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34404425",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = Path(\"/home/siamai/data/Penguin/week7/test\")         \n",
    "OUTPUT_DIR = Path(\"/home/siamai/data/Penguin/week7/json1\")   \n",
    "  \n",
    "FRAME_INTERVAL = 1         \n",
    "USE_VISIBILITY = True   \n",
    "NUM_WORKERS = mp.cpu_count() - 1 if mp.cpu_count() > 1 else 1  \n",
    "CHUNKSIZE = 2               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c18070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pose_keypoints(video_path_str, output_path_str):\n",
    "    video_path = Path(video_path_str)\n",
    "    output_path = Path(output_path_str)\n",
    "\n",
    "    mp_pose = mp_pose_module.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False)\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    results = []\n",
    "    frame_idx = 0\n",
    "    success = True\n",
    "    \n",
    "\n",
    "    with tqdm(total=total_frames, desc=f\"Processing {video_path.name}\", unit=\"frame\", position=1, leave=False) as pbar:\n",
    "        while success:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            if frame_idx % FRAME_INTERVAL == 0:\n",
    "                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                result = pose.process(image_rgb)\n",
    "\n",
    "                if result.pose_landmarks:\n",
    "                    keypoints = []\n",
    "                    for lm in result.pose_landmarks.landmark:\n",
    "                        if USE_VISIBILITY:\n",
    "                            keypoints.append([lm.x, lm.y, lm.z, lm.visibility])\n",
    "                        else:\n",
    "                            keypoints.append([lm.x, lm.y, lm.z])\n",
    "                    results.append({\n",
    "                        \"frame\": frame_idx,\n",
    "                        \"keypoints\": keypoints\n",
    "                    })\n",
    "\n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    pose.close()\n",
    "    cap.release()\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return f\"{video_path.name} done.\"\n",
    "def process_wrapper(args):\n",
    "    return extract_pose_keypoints(*args)\n",
    "\n",
    "def batch_process_all_videos(video_dir: Path, output_dir: Path):\n",
    "    video_dir = Path(video_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    video_files = list(video_dir.glob(\"*.mp4\")) + list(video_dir.glob(\"*.avi\")) + list(video_dir.glob(\"*.mov\"))\n",
    "    tasks = [(str(vf), str(output_dir / f\"{vf.stem}_keypoints.json\")) for vf in video_files]\n",
    "\n",
    "    print(f\"üöÄ Starting batch with {len(tasks)} video(s) using {NUM_WORKERS} process(es)...\\n\")\n",
    "\n",
    "    with mp.Pool(NUM_WORKERS) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap_unordered(process_wrapper, tasks, chunksize=CHUNKSIZE),\n",
    "            total=len(tasks),\n",
    "            desc=\" Batch\",\n",
    "            position=0\n",
    "        ))\n",
    "\n",
    "    print(\"\\n All videos processed:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edbf2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting batch with 5 video(s) using 11 process(es)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ Batch:   0%|          | 0/5 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750080267.412037  890134 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750080267.412010  890135 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750080267.412768  890133 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750080267.569051  890184 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "I0000 00:00:1750080267.569288  890185 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "I0000 00:00:1750080267.569533  890183 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1750080267.624498  890162 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.634883  890157 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.641421  890165 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.657995  890155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.674565  890163 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.674855  890172 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.689643  890148 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1750080267.791187  890175 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1750080267.813287  890158 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Processing s01_smiley.mp4:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 21742/26741 [05:44<01:19, 62.56frame/s]I0000 00:00:1750080694.852920  890134 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750080694.881829  962432 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "W0000 00:00:1750080694.929339  962430 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080694.968531  962427 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Processing s03_smiley.mp4:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 30580/59321 [08:06<07:35, 63.16frame/s]I0000 00:00:1750081146.479945  890133 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750081146.513178 1042460 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "W0000 00:00:1750081146.562231 1042453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750081146.594533 1042455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "üì¶ Batch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [30:21<00:00, 364.28s/it][12:30<03:03, 65.66frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® All videos processed:\n",
      "‚úÖ s03_smiley.mp4 done.\n",
      "‚úÖ s01_smiley.mp4 done.\n",
      "‚úÖ s05_smiley.mp4 done.\n",
      "‚úÖ s04_smiley.mp4 done.\n",
      "‚úÖ s02_smiley.mp4 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_process_all_videos(VIDEO_DIR, OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d86346",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"/home/siamai/data/chuniji/Arealweek7/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f164edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siamai/data/chuniji/Arealweek7/json\n"
     ]
    }
   ],
   "source": [
    "print(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c1fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 371/371 [26:27<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å dataset ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå /home/siamai/data/chuniji/Arealweek7/dataset2.json ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def timestamp_to_seconds(t):\n",
    "    m = int(t[1:3])\n",
    "    s = int(t[3:5])\n",
    "    return m * 60 + s\n",
    "\n",
    "def load_keypoints(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # Convert list to dict: frame_idx -> keypoints\n",
    "    return {item[\"frame\"]: item[\"keypoints\"] for item in data}\n",
    "\n",
    "def get_keypoint_sequence_around(frame_dict, center_frame, window=15):\n",
    "    sequence = []\n",
    "    for f in range(center_frame - window, center_frame + window + 1):\n",
    "        if f in frame_dict:\n",
    "            sequence.append(frame_dict[f])\n",
    "        else:\n",
    "            sequence.append(None)  # padding if missing\n",
    "    return sequence\n",
    "\n",
    "csv_path = \"/home/siamai/data/week7/train.csv\"\n",
    "keypoint_dir = Path(\"/home/siamai/data/chuniji/Arealweek7/json\")\n",
    "fps = 25\n",
    "window = 15  # = 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "dataset = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "    filename = row['Filename'].replace(\".mp4\", \"\")\n",
    "    timestamp = row['Time']\n",
    "    label = row[2:].values.astype(int).tolist()\n",
    "\n",
    "    sec = timestamp_to_seconds(timestamp)\n",
    "    center_frame = int(sec * fps)\n",
    "    \n",
    "    json_path = keypoint_dir / f\"{filename}_keypoints.json\"\n",
    "    if not json_path.exists():\n",
    "        continue\n",
    "\n",
    "    keypoint_dict = load_keypoints(json_path)\n",
    "    sequence = get_keypoint_sequence_around(keypoint_dict, center_frame, window=window)\n",
    "\n",
    "    dataset.append({\n",
    "        \"video\": filename,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"center_frame\": center_frame,\n",
    "        \"sequence\": sequence,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "output_path = \"/home/siamai/data/chuniji/Arealweek7/dataset2.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(dataset, f)\n",
    "print(f\"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å dataset ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå {output_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Skipped sample 50 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 51 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 52 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 53 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 54 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 55 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 56 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 57 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 58 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 59 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 60 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 61 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 62 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 63 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 64 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 65 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 66 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 67 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 68 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 69 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 70 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 71 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 72 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 73 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 74 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 75 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 76 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 77 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 78 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 79 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 80 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 81 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 82 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 83 because it contains NO valid frames to begin with.\n",
      "‚õî Skipped sample 84 because it contains NO valid frames to begin with.\n",
      "‚úÖ Data processing complete.\n",
      "‚úÖ X_seq shape: (336, 31, 66)\n",
      "‚úÖ y_seq shape: (336, 12)\n",
      "‚úÖ Data saved successfully to 'processed_dataset.npz'\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import json\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "# file_path = \"/home/siamai/data/chuniji/Arealweek7/dataset.json\"\n",
    "\n",
    "# try:\n",
    "#     with open(file_path) as f:\n",
    "#         data = json.load(f)\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"‚õîÔ∏è Error: The file was not found at {file_path}\")\n",
    "#     file_path = \"dataset.json\"\n",
    "#     try:\n",
    "#         with open(file_path) as f:\n",
    "#             data = json.load(f)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"‚õîÔ∏è Error: Also could not find {file_path}. Please check the file path.\")\n",
    "#         data = []\n",
    "\n",
    "# X_seq = []\n",
    "# y_seq = []\n",
    "\n",
    "# for i, sample in enumerate(data):\n",
    "#     sequence = []\n",
    "#     last_valid_frame = None\n",
    "\n",
    "#     for j, keypoints_per_frame in enumerate(sample[\"sequence\"]):\n",
    "#         kp_array = np.array(keypoints_per_frame)\n",
    "\n",
    "#         if kp_array.ndim == 2 and kp_array.shape[0] == 33 and kp_array.shape[1] >= 2:\n",
    "#             processed_frame = kp_array[:, :2].flatten()\n",
    "#             sequence.append(processed_frame)\n",
    "#             last_valid_frame = processed_frame\n",
    "#         else:\n",
    "#             if last_valid_frame is not None:\n",
    "#                 sequence.append(last_valid_frame)\n",
    "\n",
    "#     if len(sequence) == 0:\n",
    "#         print(f\"‚õî Skipped sample {i} because it contains NO valid frames to begin with.\")\n",
    "#         continue\n",
    "\n",
    "#     X_seq.append(np.array(sequence))\n",
    "#     y_seq.append(sample[\"label\"])\n",
    "\n",
    "# if X_seq:\n",
    "#     X_seq_padded = pad_sequences(X_seq, dtype='float32', padding='post')\n",
    "\n",
    "#     X_seq = np.array(X_seq_padded)\n",
    "#     y_seq = np.array(y_seq)\n",
    "\n",
    "#     print(\"‚úÖ Data processing complete.\")\n",
    "#     print(\"‚úÖ X_seq shape:\", X_seq.shape)\n",
    "#     print(\"‚úÖ y_seq shape:\", y_seq.shape)\n",
    "\n",
    "#     # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤: ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå .npz ---\n",
    "#     output_filename = 'processed_dataset.npz'\n",
    "#     np.savez_compressed(output_filename, X=X_seq, y=y_seq)\n",
    "#     print(f\"‚úÖ Data saved successfully to '{output_filename}'\")\n",
    "#     # -----------------------------------------------------------\n",
    "\n",
    "# else:\n",
    "#     print(\"‚õî No valid data could be processed from the JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d853c58",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m sequence \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m last_valid_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, keypoints_per_frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m     33\u001b[0m     kp_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(keypoints_per_frame)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kp_array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kp_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m33\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kp_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sequence'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "file_path = \"/home/siamai/data/Penguin/week7/json/s06_smiley_keypoints.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚õîÔ∏è Error: The file was not found at {file_path}\")\n",
    "    file_path = \"dataset.json\"\n",
    "    try:\n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚õîÔ∏è Error: Also could not find {file_path}. Please check the file path.\")\n",
    "        data = []\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
    "video_names = []\n",
    "timestamps = []\n",
    "center_frames = []\n",
    "\n",
    "for i, sample in enumerate(data):\n",
    "    sequence = []\n",
    "    last_valid_frame = None\n",
    "\n",
    "    for j, keypoints_per_frame in enumerate(sample[\"sequence\"]):\n",
    "        kp_array = np.array(keypoints_per_frame)\n",
    "\n",
    "        if kp_array.ndim == 2 and kp_array.shape[0] == 33 and kp_array.shape[1] >= 2:\n",
    "            processed_frame = kp_array[:, :2].flatten()\n",
    "            sequence.append(processed_frame)\n",
    "            last_valid_frame = processed_frame\n",
    "        else:\n",
    "            if last_valid_frame is not None:\n",
    "                sequence.append(last_valid_frame)\n",
    "\n",
    "    if len(sequence) == 0:\n",
    "        print(f\"‚õî Skipped sample {i} because it contains NO valid frames to begin with.\")\n",
    "        continue\n",
    "\n",
    "    X_seq.append(np.array(sequence))\n",
    "    y_seq.append(sample[\"label\"])\n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ sample\n",
    "    video_names.append(sample[\"video\"])\n",
    "    timestamps.append(sample[\"timestamp\"])\n",
    "    center_frames.append(sample[\"center_frame\"])\n",
    "\n",
    "if X_seq:\n",
    "    X_seq_padded = pad_sequences(X_seq, dtype='float32', padding='post')\n",
    "\n",
    "    X_seq = np.array(X_seq_padded)\n",
    "    y_seq = np.array(y_seq)\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NumPy array\n",
    "    video_names_np = np.array(video_names)\n",
    "    timestamps_np = np.array(timestamps)\n",
    "    center_frames_np = np.array(center_frames)\n",
    "\n",
    "\n",
    "    print(\"‚úÖ Data processing complete.\")\n",
    "    print(\"‚úÖ X_seq shape:\", X_seq.shape)\n",
    "    print(\"‚úÖ y_seq shape:\", y_seq.shape)\n",
    "    print(\"‚úÖ video_names shape:\", video_names_np.shape)\n",
    "    print(\"‚úÖ timestamps shape:\", timestamps_np.shape)\n",
    "    print(\"‚úÖ center_frames shape:\", center_frames_np.shape)\n",
    "\n",
    "    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤: ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå .npz ---\n",
    "    output_filename = 'processed_datasetd_with_info1.npz'\n",
    "    np.savez_compressed(output_filename, X=X_seq, y=y_seq,\n",
    "                         video_names=video_names_np,\n",
    "                         timestamps=timestamps_np,\n",
    "                         center_frames=center_frames_np)\n",
    "    print(f\"‚úÖ Data saved successfully to '{output_filename}'\")\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "else:\n",
    "    print(\"‚õî No valid data could be processed from the JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6926122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aa9c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 31, 66) (336, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"/home/siamai/data/chuniji/Arealweek7/processed_datasetd_with_info.npz\")\n",
    "X_seq = data['X']  # shape (N, T, 66)\n",
    "y_seq = data['y']  # shape (N, num_labels)\n",
    "\n",
    "print(X_seq.shape, y_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data normalized successfully.\n",
      "DataLoaders created. Train samples: 268, Val samples: 68\n",
      "Model and training components initialized.\n",
      "GestureLSTM(\n",
      "  (lstm): LSTM(66, 256, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=12, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 131.35it/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train loss: 2.0983 | Val loss: 1.8737 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.36it/s, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train loss: 1.7343 | Val loss: 1.6191 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 130.43it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train loss: 1.6679 | Val loss: 1.7467 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 132.20it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train loss: 1.6207 | Val loss: 1.7212 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 122.09it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train loss: 1.5947 | Val loss: 1.6981 | Val Acc: 25.00% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.09it/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train loss: 1.5986 | Val loss: 1.7392 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.70it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train loss: 1.5865 | Val loss: 1.6172 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 125.63it/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train loss: 1.5946 | Val loss: 1.6895 | Val Acc: 27.94% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.77it/s, loss=1.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train loss: 1.5371 | Val loss: 1.6468 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 134.36it/s, loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train loss: 1.5446 | Val loss: 1.5834 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 136.94it/s, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train loss: 1.5410 | Val loss: 1.6665 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 132.22it/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train loss: 1.4886 | Val loss: 1.6124 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.93it/s, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train loss: 1.4417 | Val loss: 1.6354 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 122.81it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train loss: 1.4835 | Val loss: 1.6355 | Val Acc: 16.18% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 125.58it/s, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train loss: 1.4560 | Val loss: 1.6762 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 132.69it/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train loss: 1.4216 | Val loss: 1.5805 | Val Acc: 27.94% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 134.81it/s, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train loss: 1.4261 | Val loss: 1.6669 | Val Acc: 27.94% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.47it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train loss: 1.3497 | Val loss: 1.6074 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 122.42it/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train loss: 1.3664 | Val loss: 1.6611 | Val Acc: 23.53% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 131.23it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train loss: 1.2989 | Val loss: 1.6477 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.67it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train loss: 1.3137 | Val loss: 1.6595 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 130.46it/s, loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train loss: 1.3167 | Val loss: 1.6532 | Val Acc: 27.94% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.99it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train loss: 1.2036 | Val loss: 1.7549 | Val Acc: 17.65% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.01it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train loss: 1.1908 | Val loss: 1.8621 | Val Acc: 20.59% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 126.23it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train loss: 1.1710 | Val loss: 1.7772 | Val Acc: 25.00% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 135.67it/s, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train loss: 1.0792 | Val loss: 1.8514 | Val Acc: 23.53% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.64it/s, loss=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train loss: 1.0915 | Val loss: 1.7006 | Val Acc: 25.00% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 136.29it/s, loss=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train loss: 1.0977 | Val loss: 1.6582 | Val Acc: 27.94% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 131.30it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train loss: 1.0904 | Val loss: 1.6543 | Val Acc: 39.71% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 130.98it/s, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train loss: 1.0453 | Val loss: 1.6381 | Val Acc: 39.71% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 136.96it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train loss: 0.9915 | Val loss: 1.6848 | Val Acc: 45.59% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.08it/s, loss=0.864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train loss: 0.9616 | Val loss: 1.6646 | Val Acc: 45.59% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 120.39it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train loss: 0.9941 | Val loss: 1.6710 | Val Acc: 42.65% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 130.70it/s, loss=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train loss: 0.9424 | Val loss: 1.6638 | Val Acc: 47.06% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.32it/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train loss: 0.9423 | Val loss: 1.7285 | Val Acc: 45.59% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 102.31it/s, loss=0.535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train loss: 0.8699 | Val loss: 1.7260 | Val Acc: 50.00% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.54it/s, loss=0.747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train loss: 0.8541 | Val loss: 1.7509 | Val Acc: 48.53% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 106.86it/s, loss=0.606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train loss: 0.8224 | Val loss: 1.7528 | Val Acc: 51.47% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 95.73it/s, loss=0.931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train loss: 0.8563 | Val loss: 1.7667 | Val Acc: 50.00% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 116.02it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train loss: 0.8433 | Val loss: 1.7715 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 98.07it/s, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train loss: 0.8151 | Val loss: 1.7928 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 111.83it/s, loss=0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train loss: 0.7830 | Val loss: 1.8425 | Val Acc: 50.00% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 116.60it/s, loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train loss: 0.8019 | Val loss: 1.8511 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 106.14it/s, loss=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train loss: 0.7613 | Val loss: 1.8463 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 127.71it/s, loss=0.929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train loss: 0.7589 | Val loss: 1.8593 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 115.11it/s, loss=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train loss: 0.7241 | Val loss: 1.8828 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.39it/s, loss=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train loss: 0.7371 | Val loss: 1.8856 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.25it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train loss: 0.7376 | Val loss: 1.9004 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 119.68it/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train loss: 0.7038 | Val loss: 1.8880 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.41it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train loss: 0.7181 | Val loss: 1.9036 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 131.97it/s, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train loss: 0.7133 | Val loss: 1.9144 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.05it/s, loss=0.458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train loss: 0.6712 | Val loss: 1.9312 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 126.11it/s, loss=0.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train loss: 0.6937 | Val loss: 1.9258 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.26it/s, loss=0.555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train loss: 0.6646 | Val loss: 1.9367 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.77it/s, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train loss: 0.6955 | Val loss: 1.9431 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.51it/s, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train loss: 0.6817 | Val loss: 1.9584 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 125.61it/s, loss=0.866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train loss: 0.6895 | Val loss: 1.9586 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 137.69it/s, loss=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train loss: 0.6794 | Val loss: 1.9516 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 119.60it/s, loss=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train loss: 0.6487 | Val loss: 1.9514 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.30it/s, loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train loss: 0.6388 | Val loss: 1.9561 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.87it/s, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train loss: 0.6404 | Val loss: 1.9614 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 130.97it/s, loss=0.585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train loss: 0.6579 | Val loss: 1.9651 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.80it/s, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train loss: 0.6668 | Val loss: 1.9699 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 128.05it/s, loss=0.799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 | Train loss: 0.6691 | Val loss: 1.9714 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 129.22it/s, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 | Train loss: 0.6364 | Val loss: 1.9709 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 117.46it/s, loss=0.759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 | Train loss: 0.6654 | Val loss: 1.9742 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 136.78it/s, loss=0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 | Train loss: 0.6343 | Val loss: 1.9723 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 130.92it/s, loss=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 | Train loss: 0.6719 | Val loss: 1.9717 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 132.89it/s, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 | Train loss: 0.6458 | Val loss: 1.9716 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 135.98it/s, loss=0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 | Train loss: 0.6576 | Val loss: 1.9735 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 134.27it/s, loss=0.554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 | Train loss: 0.6450 | Val loss: 1.9743 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 93.07it/s, loss=0.547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 | Train loss: 0.6431 | Val loss: 1.9766 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.19it/s, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 | Train loss: 0.6574 | Val loss: 1.9779 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.34it/s, loss=0.946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 | Train loss: 0.6717 | Val loss: 1.9786 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 127.31it/s, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 | Train loss: 0.6384 | Val loss: 1.9784 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 127.25it/s, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 | Train loss: 0.6457 | Val loss: 1.9786 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 106.81it/s, loss=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 | Train loss: 0.6392 | Val loss: 1.9781 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 117.79it/s, loss=0.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 | Train loss: 0.6286 | Val loss: 1.9775 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 132.92it/s, loss=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 | Train loss: 0.6137 | Val loss: 1.9773 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 118.62it/s, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 | Train loss: 0.6414 | Val loss: 1.9773 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.05it/s, loss=0.325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 | Train loss: 0.6307 | Val loss: 1.9780 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 134.47it/s, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 | Train loss: 0.6322 | Val loss: 1.9783 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 115.12it/s, loss=0.942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 | Train loss: 0.6738 | Val loss: 1.9783 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 122.17it/s, loss=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 | Train loss: 0.6641 | Val loss: 1.9783 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 131.33it/s, loss=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 | Train loss: 0.6471 | Val loss: 1.9786 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.02it/s, loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 | Train loss: 0.6300 | Val loss: 1.9787 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 124.71it/s, loss=0.628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 | Train loss: 0.6394 | Val loss: 1.9788 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 126.85it/s, loss=0.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 | Train loss: 0.6462 | Val loss: 1.9791 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 129.35it/s, loss=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 | Train loss: 0.6763 | Val loss: 1.9792 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 132.16it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 | Train loss: 0.6711 | Val loss: 1.9792 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 125.42it/s, loss=0.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 | Train loss: 0.6308 | Val loss: 1.9793 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 124.30it/s, loss=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 | Train loss: 0.6520 | Val loss: 1.9795 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 124.35it/s, loss=0.488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 | Train loss: 0.6285 | Val loss: 1.9796 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 123.22it/s, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 | Train loss: 0.6477 | Val loss: 1.9796 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 140.02it/s, loss=0.561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 | Train loss: 0.6408 | Val loss: 1.9796 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 121.96it/s, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 | Train loss: 0.6639 | Val loss: 1.9798 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 122.01it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 | Train loss: 0.6838 | Val loss: 1.9798 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 125.80it/s, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 | Train loss: 0.6488 | Val loss: 1.9799 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.78it/s, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 | Train loss: 0.6635 | Val loss: 1.9799 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 133.43it/s, loss=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 | Train loss: 0.6735 | Val loss: 1.9800 | Val Acc: 50.00% | LR: 0.000000\n",
      "Training finished.\n",
      "Model saved to gesture_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Configuration / Hyperparameters (‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà)\n",
    "# ==============================================================================\n",
    "DATA_PATH = \"/home/siamai/data/chuniji/Arealweek7/processed_datasetd_with_info.npz\"\n",
    "INPUT_DIM = 66      # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô 33 landmarks * 2 ‡∏°‡∏¥‡∏ï‡∏¥)\n",
    "HIDDEN_DIM = 256    # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á Hidden State ‡πÉ‡∏ô LSTM\n",
    "NUM_LAYERS = 3      # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡∏Ç‡∏≠‡∏á LSTM ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô\n",
    "DROPOUT_P = 0.4     # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤ Dropout (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)\n",
    "LEARNING_RATE = 0.001 # ‡πÄ‡∏û‡∏¥‡πà‡∏° Learning rate ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Epochs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "WEIGHT_DECAY = 1e-4 # ‡πÄ‡∏û‡∏¥‡πà‡∏° L2 Regularization (Weight Decay) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting\n",
    "GRAD_CLIP_NORM = 1.0 # ‡πÄ‡∏û‡∏¥‡πà‡∏° Gradient Clipping ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Exploding Gradients\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Device Configuration\n",
    "# ==============================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Data Loading and Preprocessing (Normalization)\n",
    "# ==============================================================================\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• numpy ‡∏î‡∏¥‡∏ö\n",
    "data = np.load(DATA_PATH)\n",
    "X_seq_raw = data['X']  # (N, T, 66)\n",
    "y_seq_raw = data['y']  # (N, num_labels) - ‡∏™‡∏±‡∏ô‡∏ô‡∏¥‡∏©‡∏ê‡∏≤‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô one-hot\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á y ‡∏à‡∏≤‡∏Å one-hot ‡πÄ‡∏õ‡πá‡∏ô class indices (e.g., [0,0,1,0] -> 2)\n",
    "# ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CrossEntropyLoss\n",
    "y_indices = np.argmax(y_seq_raw, axis=1)\n",
    "OUTPUT_DIM = y_seq_raw.shape[1] # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Class ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á train-val (80:20)\n",
    "num_samples = X_seq_raw.shape[0]\n",
    "split_idx = int(num_samples * 0.8)\n",
    "\n",
    "X_train_np, X_val_np = X_seq_raw[:split_idx], X_seq_raw[split_idx:]\n",
    "y_train_np, y_val_np = y_indices[:split_idx], y_indices[split_idx:]\n",
    "\n",
    "# --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô Normalization ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å) ---\n",
    "# Reshape ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• X_train ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fit scaler: (num_samples * timesteps, num_features)\n",
    "n_samples_train, n_steps_train, n_features_train = X_train_np.shape\n",
    "X_train_reshaped = X_train_np.reshape(-1, n_features_train)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞ fit scaler ‡∏Å‡∏±‡∏ö \"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\"\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "# Transform ‡∏ó‡∏±‡πâ‡∏á train ‡πÅ‡∏•‡∏∞ val data ‡∏î‡πâ‡∏ß‡∏¢ scaler ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô\n",
    "X_train_scaled = scaler.transform(X_train_reshaped).reshape(n_samples_train, n_steps_train, n_features_train)\n",
    "\n",
    "# Reshape ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• validation ‡πÄ‡∏û‡∏∑‡πà‡∏≠ transform\n",
    "n_samples_val, n_steps_val, n_features_val = X_val_np.shape\n",
    "X_val_reshaped = X_val_np.reshape(-1, n_features_val)\n",
    "X_val_scaled = scaler.transform(X_val_reshaped).reshape(n_samples_val, n_steps_val, n_features_val)\n",
    "print(\"Data normalized successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Create Tensors and Dataloaders\n",
    "# ==============================================================================\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á numpy ‡∏ó‡∏µ‡πà scale ‡πÅ‡∏•‡πâ‡∏ß -> tensor\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "\n",
    "# y ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô LongTensor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CrossEntropyLoss\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val_np, dtype=torch.long)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á dataloader\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(f\"DataLoaders created. Train samples: {len(X_train)}, Val samples: {len(X_val)}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Model Definition (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà)\n",
    "# ==============================================================================\n",
    "class GestureLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        # ‡πÉ‡∏ä‡πâ bidirectional=True ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å 2 ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        # hidden_dim ‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏π‡∏ì 2 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ bidirectional LSTM ‡πÉ‡∏´‡πâ output 2 ‡πÄ‡∏ó‡πà‡∏≤\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Sigmoid ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ CrossEntropyLoss ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out shape: (batch, seq_len, hidden_dim * 2)\n",
    "        out, _ = self.lstm(x)\n",
    "        # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ output ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "        out = out[:, -1, :]\n",
    "        # ‡∏ú‡πà‡∏≤‡∏ô linear layer ‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô logits ‡∏î‡∏¥‡∏ö‡πÜ\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Training Setup\n",
    "# ==============================================================================\n",
    "model = GestureLSTM(\n",
    "    input_dim=INPUT_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT_P\n",
    ").to(device)\n",
    "\n",
    "# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Loss Function ‡πÄ‡∏õ‡πá‡∏ô CrossEntropyLoss\n",
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏° weight_decay ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L2 Regularization ‡πÉ‡∏ô Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "# ReduceLROnPlateau Scheduler: ‡∏•‡∏î Learning Rate ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Validation Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á\n",
    "# ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ 'patience' (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏ó‡∏µ‡πà‡∏£‡∏≠) ‡∏´‡∏£‡∏∑‡∏≠ 'factor' (‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏î LR) ‡πÑ‡∏î‡πâ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "print(\"Model and training components initialized.\")\n",
    "print(model)\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. Training Loop\n",
    "# ==============================================================================\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_steps = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} - Training\")\n",
    "    for xb, yb in loop:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # ‡πÄ‡∏û‡∏¥‡πà‡∏° Gradient Clipping ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Exploding Gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss / train_steps\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_steps = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            val_loss += loss.item()\n",
    "            val_steps += 1\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted_labels = torch.max(preds, 1)\n",
    "            total_preds += yb.size(0)\n",
    "            correct_preds += (predicted_labels == yb).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / val_steps\n",
    "    val_accuracy = (correct_preds / total_preds) * 100\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "        f\"Train loss: {avg_train_loss:.4f} | \"\n",
    "        f\"Val loss: {avg_val_loss:.4f} | \"\n",
    "        f\"Val Acc: {val_accuracy:.2f}% | \"\n",
    "        f\"LR: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "    )\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
    "torch.save(model.state_dict(), 'gesture_model_final.pth')\n",
    "print(\"Model saved to gesture_model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb29e4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load your PyTorch model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/siamai/data/chuniji/Arealweek7/dgesture_model_final.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your model file path\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Run inference (no gradient needed)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load preprocessed data\n",
    "data = np.load(\"processed_dataset7.npz\", allow_pickle=True)\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "filenames = data[\"filenames\"]\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Load your PyTorch model\n",
    "model = torch.load(\"/home/siamai/data/chuniji/Arealweek7/dgesture_model_final.pth\")  # Replace with your model file path\n",
    "model.eval()\n",
    "\n",
    "# Run inference (no gradient needed)\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    predictions = torch.sigmoid(outputs)  # Use sigmoid if multi-label\n",
    "    predicted_labels = (predictions > 0.5).int().numpy()\n",
    "\n",
    "# Show some results\n",
    "for i in range(5):  # First 5 samples\n",
    "    print(f\"üé• Sample: {filenames[i]}\")\n",
    "    print(f\"‚úÖ Ground Truth: {y[i]}\")\n",
    "    print(f\"üîÆ Prediction  : {predicted_labels[i]}\")\n",
    "    print(\"--------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a8832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
