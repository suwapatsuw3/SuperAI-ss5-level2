{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbbe398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp_pose_module\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66dc8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos:   0%|          | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Processing: copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov\n",
      "   video.fps: 24\n",
      "   video.duration: 1861.82\n",
      "   video.size: [2560, 1440]\n",
      "Moviepy - Building video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4.\n",
      "MoviePy - Writing audio in copy_B52269A0-899E-43A0-A841-93F6DBDD7A9FTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos: 100%|██████████| 1/1 [00:13<00:00, 13.82s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4\n",
      "\n",
      "⚠️ Failed to convert copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "output_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "\n",
    "# Get a list of all .mov files in the input folder\n",
    "mov_files = [filename for filename in os.listdir(input_folder) if filename.endswith(\".mov\")]\n",
    "\n",
    "# Loop through all .mov files and show estimated progress with a progress bar\n",
    "for filename in tqdm(mov_files, desc='Converting videos', unit='video'):\n",
    "    input_file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    try:\n",
    "        # Load the .mov file\n",
    "        video = VideoFileClip(input_file_path).set_fps(24)\n",
    "\n",
    "        # Safely get fps\n",
    "        fps = video.fps if video.fps else 24\n",
    "\n",
    "        # Check video properties\n",
    "        if video.duration is None or video.size is None:\n",
    "            print(f\"❌ Skipping {filename} — missing duration or size\")\n",
    "            continue\n",
    "\n",
    "        # Construct output file path\n",
    "        output_filename = os.path.splitext(filename)[0] + \".mp4\"\n",
    "        output_file_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        print(f\"\\n🎬 Processing: {filename}\")\n",
    "        print(\"   video.fps:\", fps)\n",
    "        print(\"   video.duration:\", video.duration)\n",
    "        print(\"   video.size:\", video.size)\n",
    "\n",
    "        # Write the video to output\n",
    "        video.write_videofile(output_file_path, codec='libx264', fps=fps)\n",
    "\n",
    "        # Manual frame progress bar (optional)\n",
    "        total_frames = int(video.duration * fps)\n",
    "        progress = 0\n",
    "        with tqdm(total=total_frames, desc=f'{filename}', unit='frame') as pbar:\n",
    "            while progress < total_frames:\n",
    "                progress = video.reader.nframes\n",
    "                pbar.update(progress - pbar.n)\n",
    "\n",
    "        video.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to convert {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b17353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos:   0%|          | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Processing: copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos:   0%|          | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   video.fps: 24.0\n",
      "   video.duration: 1861.82\n",
      "   video.size: [2560, 1440]\n",
      "   video.has_audio: True\n",
      "Moviepy - Building video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4.\n",
      "MoviePy - Writing audio in copy_B52269A0-899E-43A0-A841-93F6DBDD7A9FTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting videos: 100%|██████████| 1/1 [00:13<00:00, 13.50s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/siamai/data/Penguin/week7/test/copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mp4\n",
      "\n",
      "⚠️ Failed to convert copy_B52269A0-899E-43A0-A841-93F6DBDD7A9F.mov: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "output_folder = \"/home/siamai/data/Penguin/week7/test\"\n",
    "\n",
    "mov_files = [f for f in os.listdir(input_folder) if f.endswith(\".mov\")]\n",
    "\n",
    "for filename in tqdm(mov_files, desc='Converting videos', unit='video'):\n",
    "    try:\n",
    "        print(f\"\\n🎬 Processing: {filename}\")\n",
    "        input_file_path = os.path.join(input_folder, filename)\n",
    "        output_filename = os.path.splitext(filename)[0] + \".mp4\"\n",
    "        output_file_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        video = VideoFileClip(input_file_path)\n",
    "        fps = video.fps or 24\n",
    "        duration = video.duration or 0\n",
    "        size = video.size\n",
    "\n",
    "        print(\"   video.fps:\", fps)\n",
    "        print(\"   video.duration:\", duration)\n",
    "        print(\"   video.size:\", size)\n",
    "        print(\"   video.has_audio:\", video.audio is not None)\n",
    "\n",
    "        # Set fps explicitly\n",
    "        video = video.set_fps(fps)\n",
    "\n",
    "        # Check and validate audio\n",
    "        has_audio = False\n",
    "        if video.audio is not None:\n",
    "            try:\n",
    "                _ = video.audio.fps\n",
    "                _ = video.audio.duration\n",
    "                _ = video.audio.nchannels\n",
    "                has_audio = True\n",
    "            except Exception as audio_err:\n",
    "                print(\"⚠️ Corrupted audio detected — stripping audio.\")\n",
    "                video = video.without_audio()\n",
    "\n",
    "        # Write video with or without audio\n",
    "        video.write_videofile(\n",
    "            output_file_path,\n",
    "            codec='libx264',\n",
    "            fps=fps,\n",
    "            audio=has_audio,\n",
    "            audio_codec='aac' if has_audio else None,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to convert {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7605172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s06_smiley.mp4: FPS = 25.0\n"
     ]
    }
   ],
   "source": [
    "video_dir = Path('/home/siamai/data/Penguin/week7/test')\n",
    "\n",
    "for video_file in video_dir.glob(\"*.mp4\"):\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"{video_file.name}: FPS = {fps}\")\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34404425",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = Path(\"/home/siamai/data/Penguin/week7/test\")         \n",
    "OUTPUT_DIR = Path(\"/home/siamai/data/Penguin/week7/json1\")   \n",
    "  \n",
    "FRAME_INTERVAL = 1         \n",
    "USE_VISIBILITY = True   \n",
    "NUM_WORKERS = mp.cpu_count() - 1 if mp.cpu_count() > 1 else 1  \n",
    "CHUNKSIZE = 2               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c18070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pose_keypoints(video_path_str, output_path_str):\n",
    "    video_path = Path(video_path_str)\n",
    "    output_path = Path(output_path_str)\n",
    "\n",
    "    mp_pose = mp_pose_module.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False)\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    results = []\n",
    "    frame_idx = 0\n",
    "    success = True\n",
    "    \n",
    "\n",
    "    with tqdm(total=total_frames, desc=f\"Processing {video_path.name}\", unit=\"frame\", position=1, leave=False) as pbar:\n",
    "        while success:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            if frame_idx % FRAME_INTERVAL == 0:\n",
    "                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                result = pose.process(image_rgb)\n",
    "\n",
    "                if result.pose_landmarks:\n",
    "                    keypoints = []\n",
    "                    for lm in result.pose_landmarks.landmark:\n",
    "                        if USE_VISIBILITY:\n",
    "                            keypoints.append([lm.x, lm.y, lm.z, lm.visibility])\n",
    "                        else:\n",
    "                            keypoints.append([lm.x, lm.y, lm.z])\n",
    "                    results.append({\n",
    "                        \"frame\": frame_idx,\n",
    "                        \"keypoints\": keypoints\n",
    "                    })\n",
    "\n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    pose.close()\n",
    "    cap.release()\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return f\"{video_path.name} done.\"\n",
    "def process_wrapper(args):\n",
    "    return extract_pose_keypoints(*args)\n",
    "\n",
    "def batch_process_all_videos(video_dir: Path, output_dir: Path):\n",
    "    video_dir = Path(video_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    video_files = list(video_dir.glob(\"*.mp4\")) + list(video_dir.glob(\"*.avi\")) + list(video_dir.glob(\"*.mov\"))\n",
    "    tasks = [(str(vf), str(output_dir / f\"{vf.stem}_keypoints.json\")) for vf in video_files]\n",
    "\n",
    "    print(f\"🚀 Starting batch with {len(tasks)} video(s) using {NUM_WORKERS} process(es)...\\n\")\n",
    "\n",
    "    with mp.Pool(NUM_WORKERS) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap_unordered(process_wrapper, tasks, chunksize=CHUNKSIZE),\n",
    "            total=len(tasks),\n",
    "            desc=\" Batch\",\n",
    "            position=0\n",
    "        ))\n",
    "\n",
    "    print(\"\\n All videos processed:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edbf2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting batch with 5 video(s) using 11 process(es)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 Batch:   0%|          | 0/5 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750080267.412037  890134 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750080267.412010  890135 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750080267.412768  890133 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750080267.569051  890184 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "I0000 00:00:1750080267.569288  890185 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "I0000 00:00:1750080267.569533  890183 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1750080267.624498  890162 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.634883  890157 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.641421  890165 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.657995  890155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.674565  890163 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.674855  890172 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080267.689643  890148 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1750080267.791187  890175 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1750080267.813287  890158 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Processing s01_smiley.mp4:  81%|████████▏ | 21742/26741 [05:44<01:19, 62.56frame/s]I0000 00:00:1750080694.852920  890134 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750080694.881829  962432 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "W0000 00:00:1750080694.929339  962430 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750080694.968531  962427 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Processing s03_smiley.mp4:  52%|█████▏    | 30580/59321 [08:06<07:35, 63.16frame/s]I0000 00:00:1750081146.479945  890133 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1750081146.513178 1042460 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 575.57.08), renderer: NVIDIA H100 80GB HBM3/PCIe/SSE2\n",
      "W0000 00:00:1750081146.562231 1042453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750081146.594533 1042455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "📦 Batch: 100%|██████████| 5/5 [30:21<00:00, 364.28s/it][12:30<03:03, 65.66frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ All videos processed:\n",
      "✅ s03_smiley.mp4 done.\n",
      "✅ s01_smiley.mp4 done.\n",
      "✅ s05_smiley.mp4 done.\n",
      "✅ s04_smiley.mp4 done.\n",
      "✅ s02_smiley.mp4 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_process_all_videos(VIDEO_DIR, OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d86346",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"/home/siamai/data/chuniji/Arealweek7/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f164edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siamai/data/chuniji/Arealweek7/json\n"
     ]
    }
   ],
   "source": [
    "print(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c1fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371/371 [26:27<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "บันทึก dataset ลงไฟล์ /home/siamai/data/chuniji/Arealweek7/dataset2.json เรียบร้อย\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def timestamp_to_seconds(t):\n",
    "    m = int(t[1:3])\n",
    "    s = int(t[3:5])\n",
    "    return m * 60 + s\n",
    "\n",
    "def load_keypoints(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # Convert list to dict: frame_idx -> keypoints\n",
    "    return {item[\"frame\"]: item[\"keypoints\"] for item in data}\n",
    "\n",
    "def get_keypoint_sequence_around(frame_dict, center_frame, window=15):\n",
    "    sequence = []\n",
    "    for f in range(center_frame - window, center_frame + window + 1):\n",
    "        if f in frame_dict:\n",
    "            sequence.append(frame_dict[f])\n",
    "        else:\n",
    "            sequence.append(None)  # padding if missing\n",
    "    return sequence\n",
    "\n",
    "csv_path = \"/home/siamai/data/week7/train.csv\"\n",
    "keypoint_dir = Path(\"/home/siamai/data/chuniji/Arealweek7/json\")\n",
    "fps = 25\n",
    "window = 15  # = 1 วินาที\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "dataset = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # โค้ดเดิมของคุณ\n",
    "    filename = row['Filename'].replace(\".mp4\", \"\")\n",
    "    timestamp = row['Time']\n",
    "    label = row[2:].values.astype(int).tolist()\n",
    "\n",
    "    sec = timestamp_to_seconds(timestamp)\n",
    "    center_frame = int(sec * fps)\n",
    "    \n",
    "    json_path = keypoint_dir / f\"{filename}_keypoints.json\"\n",
    "    if not json_path.exists():\n",
    "        continue\n",
    "\n",
    "    keypoint_dict = load_keypoints(json_path)\n",
    "    sequence = get_keypoint_sequence_around(keypoint_dict, center_frame, window=window)\n",
    "\n",
    "    dataset.append({\n",
    "        \"video\": filename,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"center_frame\": center_frame,\n",
    "        \"sequence\": sequence,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "output_path = \"/home/siamai/data/chuniji/Arealweek7/dataset2.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(dataset, f)\n",
    "print(f\"บันทึก dataset ลงไฟล์ {output_path} เรียบร้อย\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Skipped sample 50 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 51 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 52 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 53 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 54 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 55 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 56 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 57 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 58 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 59 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 60 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 61 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 62 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 63 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 64 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 65 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 66 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 67 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 68 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 69 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 70 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 71 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 72 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 73 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 74 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 75 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 76 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 77 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 78 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 79 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 80 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 81 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 82 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 83 because it contains NO valid frames to begin with.\n",
      "⛔ Skipped sample 84 because it contains NO valid frames to begin with.\n",
      "✅ Data processing complete.\n",
      "✅ X_seq shape: (336, 31, 66)\n",
      "✅ y_seq shape: (336, 12)\n",
      "✅ Data saved successfully to 'processed_dataset.npz'\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import json\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# # ระบุตำแหน่งไฟล์ของคุณ\n",
    "# file_path = \"/home/siamai/data/chuniji/Arealweek7/dataset.json\"\n",
    "\n",
    "# try:\n",
    "#     with open(file_path) as f:\n",
    "#         data = json.load(f)\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"⛔️ Error: The file was not found at {file_path}\")\n",
    "#     file_path = \"dataset.json\"\n",
    "#     try:\n",
    "#         with open(file_path) as f:\n",
    "#             data = json.load(f)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"⛔️ Error: Also could not find {file_path}. Please check the file path.\")\n",
    "#         data = []\n",
    "\n",
    "# X_seq = []\n",
    "# y_seq = []\n",
    "\n",
    "# for i, sample in enumerate(data):\n",
    "#     sequence = []\n",
    "#     last_valid_frame = None\n",
    "\n",
    "#     for j, keypoints_per_frame in enumerate(sample[\"sequence\"]):\n",
    "#         kp_array = np.array(keypoints_per_frame)\n",
    "\n",
    "#         if kp_array.ndim == 2 and kp_array.shape[0] == 33 and kp_array.shape[1] >= 2:\n",
    "#             processed_frame = kp_array[:, :2].flatten()\n",
    "#             sequence.append(processed_frame)\n",
    "#             last_valid_frame = processed_frame\n",
    "#         else:\n",
    "#             if last_valid_frame is not None:\n",
    "#                 sequence.append(last_valid_frame)\n",
    "\n",
    "#     if len(sequence) == 0:\n",
    "#         print(f\"⛔ Skipped sample {i} because it contains NO valid frames to begin with.\")\n",
    "#         continue\n",
    "\n",
    "#     X_seq.append(np.array(sequence))\n",
    "#     y_seq.append(sample[\"label\"])\n",
    "\n",
    "# if X_seq:\n",
    "#     X_seq_padded = pad_sequences(X_seq, dtype='float32', padding='post')\n",
    "\n",
    "#     X_seq = np.array(X_seq_padded)\n",
    "#     y_seq = np.array(y_seq)\n",
    "\n",
    "#     print(\"✅ Data processing complete.\")\n",
    "#     print(\"✅ X_seq shape:\", X_seq.shape)\n",
    "#     print(\"✅ y_seq shape:\", y_seq.shape)\n",
    "\n",
    "#     # --- ส่วนที่เพิ่มเข้ามา: การบันทึกข้อมูลเป็นไฟล์ .npz ---\n",
    "#     output_filename = 'processed_dataset.npz'\n",
    "#     np.savez_compressed(output_filename, X=X_seq, y=y_seq)\n",
    "#     print(f\"✅ Data saved successfully to '{output_filename}'\")\n",
    "#     # -----------------------------------------------------------\n",
    "\n",
    "# else:\n",
    "#     print(\"⛔ No valid data could be processed from the JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d853c58",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m sequence \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m last_valid_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, keypoints_per_frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m     33\u001b[0m     kp_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(keypoints_per_frame)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kp_array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kp_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m33\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kp_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sequence'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ระบุตำแหน่งไฟล์ของคุณ\n",
    "file_path = \"/home/siamai/data/Penguin/week7/json/s06_smiley_keypoints.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"⛔️ Error: The file was not found at {file_path}\")\n",
    "    file_path = \"dataset.json\"\n",
    "    try:\n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⛔️ Error: Also could not find {file_path}. Please check the file path.\")\n",
    "        data = []\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "# เพิ่มลิสต์สำหรับเก็บข้อมูลเพิ่มเติม\n",
    "video_names = []\n",
    "timestamps = []\n",
    "center_frames = []\n",
    "\n",
    "for i, sample in enumerate(data):\n",
    "    sequence = []\n",
    "    last_valid_frame = None\n",
    "\n",
    "    for j, keypoints_per_frame in enumerate(sample[\"sequence\"]):\n",
    "        kp_array = np.array(keypoints_per_frame)\n",
    "\n",
    "        if kp_array.ndim == 2 and kp_array.shape[0] == 33 and kp_array.shape[1] >= 2:\n",
    "            processed_frame = kp_array[:, :2].flatten()\n",
    "            sequence.append(processed_frame)\n",
    "            last_valid_frame = processed_frame\n",
    "        else:\n",
    "            if last_valid_frame is not None:\n",
    "                sequence.append(last_valid_frame)\n",
    "\n",
    "    if len(sequence) == 0:\n",
    "        print(f\"⛔ Skipped sample {i} because it contains NO valid frames to begin with.\")\n",
    "        continue\n",
    "\n",
    "    X_seq.append(np.array(sequence))\n",
    "    y_seq.append(sample[\"label\"])\n",
    "    # เพิ่มข้อมูลเพิ่มเติมสำหรับแต่ละ sample\n",
    "    video_names.append(sample[\"video\"])\n",
    "    timestamps.append(sample[\"timestamp\"])\n",
    "    center_frames.append(sample[\"center_frame\"])\n",
    "\n",
    "if X_seq:\n",
    "    X_seq_padded = pad_sequences(X_seq, dtype='float32', padding='post')\n",
    "\n",
    "    X_seq = np.array(X_seq_padded)\n",
    "    y_seq = np.array(y_seq)\n",
    "    # แปลงลิสต์ข้อมูลเพิ่มเติมให้เป็น NumPy array\n",
    "    video_names_np = np.array(video_names)\n",
    "    timestamps_np = np.array(timestamps)\n",
    "    center_frames_np = np.array(center_frames)\n",
    "\n",
    "\n",
    "    print(\"✅ Data processing complete.\")\n",
    "    print(\"✅ X_seq shape:\", X_seq.shape)\n",
    "    print(\"✅ y_seq shape:\", y_seq.shape)\n",
    "    print(\"✅ video_names shape:\", video_names_np.shape)\n",
    "    print(\"✅ timestamps shape:\", timestamps_np.shape)\n",
    "    print(\"✅ center_frames shape:\", center_frames_np.shape)\n",
    "\n",
    "    # --- ส่วนที่เพิ่มเข้ามา: การบันทึกข้อมูลเป็นไฟล์ .npz ---\n",
    "    output_filename = 'processed_datasetd_with_info1.npz'\n",
    "    np.savez_compressed(output_filename, X=X_seq, y=y_seq,\n",
    "                         video_names=video_names_np,\n",
    "                         timestamps=timestamps_np,\n",
    "                         center_frames=center_frames_np)\n",
    "    print(f\"✅ Data saved successfully to '{output_filename}'\")\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "else:\n",
    "    print(\"⛔ No valid data could be processed from the JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6926122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aa9c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 31, 66) (336, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"/home/siamai/data/chuniji/Arealweek7/processed_datasetd_with_info.npz\")\n",
    "X_seq = data['X']  # shape (N, T, 66)\n",
    "y_seq = data['y']  # shape (N, num_labels)\n",
    "\n",
    "print(X_seq.shape, y_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data normalized successfully.\n",
      "DataLoaders created. Train samples: 268, Val samples: 68\n",
      "Model and training components initialized.\n",
      "GestureLSTM(\n",
      "  (lstm): LSTM(66, 256, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=12, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 131.35it/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train loss: 2.0983 | Val loss: 1.8737 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.36it/s, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train loss: 1.7343 | Val loss: 1.6191 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 130.43it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train loss: 1.6679 | Val loss: 1.7467 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 132.20it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train loss: 1.6207 | Val loss: 1.7212 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 122.09it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train loss: 1.5947 | Val loss: 1.6981 | Val Acc: 25.00% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.09it/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train loss: 1.5986 | Val loss: 1.7392 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.70it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train loss: 1.5865 | Val loss: 1.6172 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 125.63it/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train loss: 1.5946 | Val loss: 1.6895 | Val Acc: 27.94% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.77it/s, loss=1.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train loss: 1.5371 | Val loss: 1.6468 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 134.36it/s, loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train loss: 1.5446 | Val loss: 1.5834 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 136.94it/s, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train loss: 1.5410 | Val loss: 1.6665 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 132.22it/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train loss: 1.4886 | Val loss: 1.6124 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.93it/s, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train loss: 1.4417 | Val loss: 1.6354 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 122.81it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train loss: 1.4835 | Val loss: 1.6355 | Val Acc: 16.18% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 125.58it/s, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train loss: 1.4560 | Val loss: 1.6762 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 132.69it/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train loss: 1.4216 | Val loss: 1.5805 | Val Acc: 27.94% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 134.81it/s, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train loss: 1.4261 | Val loss: 1.6669 | Val Acc: 27.94% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.47it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train loss: 1.3497 | Val loss: 1.6074 | Val Acc: 20.59% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 122.42it/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train loss: 1.3664 | Val loss: 1.6611 | Val Acc: 23.53% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 131.23it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train loss: 1.2989 | Val loss: 1.6477 | Val Acc: 22.06% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.67it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train loss: 1.3137 | Val loss: 1.6595 | Val Acc: 19.12% | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 130.46it/s, loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train loss: 1.3167 | Val loss: 1.6532 | Val Acc: 27.94% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.99it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train loss: 1.2036 | Val loss: 1.7549 | Val Acc: 17.65% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.01it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train loss: 1.1908 | Val loss: 1.8621 | Val Acc: 20.59% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 126.23it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train loss: 1.1710 | Val loss: 1.7772 | Val Acc: 25.00% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 135.67it/s, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train loss: 1.0792 | Val loss: 1.8514 | Val Acc: 23.53% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.64it/s, loss=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train loss: 1.0915 | Val loss: 1.7006 | Val Acc: 25.00% | LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 136.29it/s, loss=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train loss: 1.0977 | Val loss: 1.6582 | Val Acc: 27.94% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 131.30it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train loss: 1.0904 | Val loss: 1.6543 | Val Acc: 39.71% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 130.98it/s, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train loss: 1.0453 | Val loss: 1.6381 | Val Acc: 39.71% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 136.96it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train loss: 0.9915 | Val loss: 1.6848 | Val Acc: 45.59% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.08it/s, loss=0.864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train loss: 0.9616 | Val loss: 1.6646 | Val Acc: 45.59% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 120.39it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train loss: 0.9941 | Val loss: 1.6710 | Val Acc: 42.65% | LR: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 130.70it/s, loss=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train loss: 0.9424 | Val loss: 1.6638 | Val Acc: 47.06% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.32it/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train loss: 0.9423 | Val loss: 1.7285 | Val Acc: 45.59% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 102.31it/s, loss=0.535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train loss: 0.8699 | Val loss: 1.7260 | Val Acc: 50.00% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.54it/s, loss=0.747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train loss: 0.8541 | Val loss: 1.7509 | Val Acc: 48.53% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 106.86it/s, loss=0.606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train loss: 0.8224 | Val loss: 1.7528 | Val Acc: 51.47% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 95.73it/s, loss=0.931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train loss: 0.8563 | Val loss: 1.7667 | Val Acc: 50.00% | LR: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 116.02it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train loss: 0.8433 | Val loss: 1.7715 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 98.07it/s, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train loss: 0.8151 | Val loss: 1.7928 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 111.83it/s, loss=0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train loss: 0.7830 | Val loss: 1.8425 | Val Acc: 50.00% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 116.60it/s, loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train loss: 0.8019 | Val loss: 1.8511 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 106.14it/s, loss=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train loss: 0.7613 | Val loss: 1.8463 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 127.71it/s, loss=0.929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train loss: 0.7589 | Val loss: 1.8593 | Val Acc: 51.47% | LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 115.11it/s, loss=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train loss: 0.7241 | Val loss: 1.8828 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.39it/s, loss=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train loss: 0.7371 | Val loss: 1.8856 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.25it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train loss: 0.7376 | Val loss: 1.9004 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 119.68it/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train loss: 0.7038 | Val loss: 1.8880 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.41it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train loss: 0.7181 | Val loss: 1.9036 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 131.97it/s, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train loss: 0.7133 | Val loss: 1.9144 | Val Acc: 50.00% | LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.05it/s, loss=0.458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train loss: 0.6712 | Val loss: 1.9312 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 126.11it/s, loss=0.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train loss: 0.6937 | Val loss: 1.9258 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.26it/s, loss=0.555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train loss: 0.6646 | Val loss: 1.9367 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.77it/s, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train loss: 0.6955 | Val loss: 1.9431 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.51it/s, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train loss: 0.6817 | Val loss: 1.9584 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 125.61it/s, loss=0.866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train loss: 0.6895 | Val loss: 1.9586 | Val Acc: 50.00% | LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 137.69it/s, loss=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train loss: 0.6794 | Val loss: 1.9516 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 119.60it/s, loss=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train loss: 0.6487 | Val loss: 1.9514 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.30it/s, loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train loss: 0.6388 | Val loss: 1.9561 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.87it/s, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train loss: 0.6404 | Val loss: 1.9614 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 130.97it/s, loss=0.585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train loss: 0.6579 | Val loss: 1.9651 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.80it/s, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train loss: 0.6668 | Val loss: 1.9699 | Val Acc: 50.00% | LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 128.05it/s, loss=0.799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 | Train loss: 0.6691 | Val loss: 1.9714 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 129.22it/s, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 | Train loss: 0.6364 | Val loss: 1.9709 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 117.46it/s, loss=0.759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 | Train loss: 0.6654 | Val loss: 1.9742 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 136.78it/s, loss=0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 | Train loss: 0.6343 | Val loss: 1.9723 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 130.92it/s, loss=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 | Train loss: 0.6719 | Val loss: 1.9717 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 132.89it/s, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 | Train loss: 0.6458 | Val loss: 1.9716 | Val Acc: 50.00% | LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 135.98it/s, loss=0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 | Train loss: 0.6576 | Val loss: 1.9735 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 134.27it/s, loss=0.554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 | Train loss: 0.6450 | Val loss: 1.9743 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 93.07it/s, loss=0.547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 | Train loss: 0.6431 | Val loss: 1.9766 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.19it/s, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 | Train loss: 0.6574 | Val loss: 1.9779 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.34it/s, loss=0.946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 | Train loss: 0.6717 | Val loss: 1.9786 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 127.31it/s, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 | Train loss: 0.6384 | Val loss: 1.9784 | Val Acc: 50.00% | LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 127.25it/s, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 | Train loss: 0.6457 | Val loss: 1.9786 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 106.81it/s, loss=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 | Train loss: 0.6392 | Val loss: 1.9781 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 117.79it/s, loss=0.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 | Train loss: 0.6286 | Val loss: 1.9775 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 132.92it/s, loss=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 | Train loss: 0.6137 | Val loss: 1.9773 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 118.62it/s, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 | Train loss: 0.6414 | Val loss: 1.9773 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.05it/s, loss=0.325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 | Train loss: 0.6307 | Val loss: 1.9780 | Val Acc: 50.00% | LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 134.47it/s, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 | Train loss: 0.6322 | Val loss: 1.9783 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 115.12it/s, loss=0.942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 | Train loss: 0.6738 | Val loss: 1.9783 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 122.17it/s, loss=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 | Train loss: 0.6641 | Val loss: 1.9783 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 131.33it/s, loss=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 | Train loss: 0.6471 | Val loss: 1.9786 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.02it/s, loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 | Train loss: 0.6300 | Val loss: 1.9787 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 124.71it/s, loss=0.628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 | Train loss: 0.6394 | Val loss: 1.9788 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 126.85it/s, loss=0.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 | Train loss: 0.6462 | Val loss: 1.9791 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 129.35it/s, loss=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 | Train loss: 0.6763 | Val loss: 1.9792 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 132.16it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 | Train loss: 0.6711 | Val loss: 1.9792 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 125.42it/s, loss=0.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 | Train loss: 0.6308 | Val loss: 1.9793 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 124.30it/s, loss=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 | Train loss: 0.6520 | Val loss: 1.9795 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 124.35it/s, loss=0.488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 | Train loss: 0.6285 | Val loss: 1.9796 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 123.22it/s, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 | Train loss: 0.6477 | Val loss: 1.9796 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 140.02it/s, loss=0.561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 | Train loss: 0.6408 | Val loss: 1.9796 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 121.96it/s, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 | Train loss: 0.6639 | Val loss: 1.9798 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 122.01it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 | Train loss: 0.6838 | Val loss: 1.9798 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 125.80it/s, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 | Train loss: 0.6488 | Val loss: 1.9799 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.78it/s, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 | Train loss: 0.6635 | Val loss: 1.9799 | Val Acc: 50.00% | LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 - Training: 100%|██████████| 9/9 [00:00<00:00, 133.43it/s, loss=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 | Train loss: 0.6735 | Val loss: 1.9800 | Val Acc: 50.00% | LR: 0.000000\n",
      "Training finished.\n",
      "Model saved to gesture_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Configuration / Hyperparameters (ปรับแก้ค่าต่างๆ ที่นี่)\n",
    "# ==============================================================================\n",
    "DATA_PATH = \"/home/siamai/data/chuniji/Arealweek7/processed_datasetd_with_info.npz\"\n",
    "INPUT_DIM = 66      # จำนวน features ของข้อมูล (เช่น 33 landmarks * 2 มิติ)\n",
    "HIDDEN_DIM = 256    # ขนาดของ Hidden State ใน LSTM\n",
    "NUM_LAYERS = 3      # จำนวนชั้นของ LSTM ที่ซ้อนกัน\n",
    "DROPOUT_P = 0.4     # อัตรา Dropout (เพิ่มขึ้นเล็กน้อยเพื่อป้องกัน Overfitting จากโมเดลที่ซับซ้อนขึ้น)\n",
    "LEARNING_RATE = 0.001 # เพิ่ม Learning rate เริ่มต้น\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100    # เพิ่มจำนวน Epochs เพื่อให้โมเดลมีเวลาเรียนรู้มากขึ้น\n",
    "WEIGHT_DECAY = 1e-4 # เพิ่ม L2 Regularization (Weight Decay) เพื่อลด Overfitting\n",
    "GRAD_CLIP_NORM = 1.0 # เพิ่ม Gradient Clipping เพื่อป้องกัน Exploding Gradients\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Device Configuration\n",
    "# ==============================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Data Loading and Preprocessing (Normalization)\n",
    "# ==============================================================================\n",
    "# โหลดข้อมูล numpy ดิบ\n",
    "data = np.load(DATA_PATH)\n",
    "X_seq_raw = data['X']  # (N, T, 66)\n",
    "y_seq_raw = data['y']  # (N, num_labels) - สันนิษฐานว่าเป็น one-hot\n",
    "\n",
    "# แปลง y จาก one-hot เป็น class indices (e.g., [0,0,1,0] -> 2)\n",
    "# ซึ่งจำเป็นสำหรับ CrossEntropyLoss\n",
    "y_indices = np.argmax(y_seq_raw, axis=1)\n",
    "OUTPUT_DIM = y_seq_raw.shape[1] # จำนวน Class ทั้งหมด\n",
    "\n",
    "# แบ่ง train-val (80:20)\n",
    "num_samples = X_seq_raw.shape[0]\n",
    "split_idx = int(num_samples * 0.8)\n",
    "\n",
    "X_train_np, X_val_np = X_seq_raw[:split_idx], X_seq_raw[split_idx:]\n",
    "y_train_np, y_val_np = y_indices[:split_idx], y_indices[split_idx:]\n",
    "\n",
    "# --- ขั้นตอน Normalization ที่เพิ่มเข้ามา (สำคัญมาก) ---\n",
    "# Reshape ข้อมูล X_train เพื่อ fit scaler: (num_samples * timesteps, num_features)\n",
    "n_samples_train, n_steps_train, n_features_train = X_train_np.shape\n",
    "X_train_reshaped = X_train_np.reshape(-1, n_features_train)\n",
    "\n",
    "# สร้างและ fit scaler กับ \"ข้อมูล Train เท่านั้น\"\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "# Transform ทั้ง train และ val data ด้วย scaler ตัวเดียวกัน\n",
    "X_train_scaled = scaler.transform(X_train_reshaped).reshape(n_samples_train, n_steps_train, n_features_train)\n",
    "\n",
    "# Reshape ข้อมูล validation เพื่อ transform\n",
    "n_samples_val, n_steps_val, n_features_val = X_val_np.shape\n",
    "X_val_reshaped = X_val_np.reshape(-1, n_features_val)\n",
    "X_val_scaled = scaler.transform(X_val_reshaped).reshape(n_samples_val, n_steps_val, n_features_val)\n",
    "print(\"Data normalized successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Create Tensors and Dataloaders\n",
    "# ==============================================================================\n",
    "# แปลง numpy ที่ scale แล้ว -> tensor\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "\n",
    "# y ต้องเป็น LongTensor สำหรับ CrossEntropyLoss\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val_np, dtype=torch.long)\n",
    "\n",
    "# สร้าง dataloader\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(f\"DataLoaders created. Train samples: {len(X_train)}, Val samples: {len(X_val)}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Model Definition (ปรับปรุงใหม่)\n",
    "# ==============================================================================\n",
    "class GestureLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        # ใช้ bidirectional=True เพื่อให้โมเดลเรียนรู้จาก 2 ทิศทาง\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        # hidden_dim ต้องคูณ 2 เพราะ bidirectional LSTM ให้ output 2 เท่า\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        # ไม่ต้องใช้ Sigmoid แล้ว เพราะ CrossEntropyLoss จัดการให้\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out shape: (batch, seq_len, hidden_dim * 2)\n",
    "        out, _ = self.lstm(x)\n",
    "        # เอาเฉพาะ output ของเฟรมสุดท้าย\n",
    "        out = out[:, -1, :]\n",
    "        # ผ่าน linear layer ได้เป็น logits ดิบๆ\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Training Setup\n",
    "# ==============================================================================\n",
    "model = GestureLSTM(\n",
    "    input_dim=INPUT_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT_P\n",
    ").to(device)\n",
    "\n",
    "# เปลี่ยน Loss Function เป็น CrossEntropyLoss\n",
    "# เพิ่ม weight_decay สำหรับ L2 Regularization ใน Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "# ReduceLROnPlateau Scheduler: ลด Learning Rate เมื่อ Validation Loss ไม่ลดลง\n",
    "# สามารถปรับค่า 'patience' (จำนวน epoch ที่รอ) หรือ 'factor' (อัตราส่วนการลด LR) ได้หากจำเป็น\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "print(\"Model and training components initialized.\")\n",
    "print(model)\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. Training Loop\n",
    "# ==============================================================================\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_steps = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} - Training\")\n",
    "    for xb, yb in loop:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # เพิ่ม Gradient Clipping เพื่อป้องกัน Exploding Gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss / train_steps\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_steps = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            val_loss += loss.item()\n",
    "            val_steps += 1\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted_labels = torch.max(preds, 1)\n",
    "            total_preds += yb.size(0)\n",
    "            correct_preds += (predicted_labels == yb).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / val_steps\n",
    "    val_accuracy = (correct_preds / total_preds) * 100\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "        f\"Train loss: {avg_train_loss:.4f} | \"\n",
    "        f\"Val loss: {avg_val_loss:.4f} | \"\n",
    "        f\"Val Acc: {val_accuracy:.2f}% | \"\n",
    "        f\"LR: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "    )\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# สามารถเพิ่มโค้ดสำหรับบันทึกโมเดลได้ที่นี่\n",
    "torch.save(model.state_dict(), 'gesture_model_final.pth')\n",
    "print(\"Model saved to gesture_model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb29e4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load your PyTorch model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/siamai/data/chuniji/Arealweek7/dgesture_model_final.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your model file path\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Run inference (no gradient needed)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load preprocessed data\n",
    "data = np.load(\"processed_dataset7.npz\", allow_pickle=True)\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "filenames = data[\"filenames\"]\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Load your PyTorch model\n",
    "model = torch.load(\"/home/siamai/data/chuniji/Arealweek7/dgesture_model_final.pth\")  # Replace with your model file path\n",
    "model.eval()\n",
    "\n",
    "# Run inference (no gradient needed)\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    predictions = torch.sigmoid(outputs)  # Use sigmoid if multi-label\n",
    "    predicted_labels = (predictions > 0.5).int().numpy()\n",
    "\n",
    "# Show some results\n",
    "for i in range(5):  # First 5 samples\n",
    "    print(f\"🎥 Sample: {filenames[i]}\")\n",
    "    print(f\"✅ Ground Truth: {y[i]}\")\n",
    "    print(f\"🔮 Prediction  : {predicted_labels[i]}\")\n",
    "    print(\"--------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a8832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
